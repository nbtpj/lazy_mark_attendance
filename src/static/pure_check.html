<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <title>Camera Background with Pause</title>
    <style>
        body, html {
            height: 100%;
            margin: 0;
            font-family: Arial, Helvetica, sans-serif;
        }

        #bgVideo {
            position: fixed;
            inset: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 0;
            background: #000;
        }

        .ui {
            position: relative;
            z-index: 10;
            padding: 12px;
            display: flex;
            gap: 8px;
            align-items: center;
            background: rgba(0, 0, 0, 0.35);
            color: #fff;
            border-radius: 8px;
            margin: 12px;
            width: max-content;
        }

        label {
            font-size: 14px;
            margin-right: 6px;
        }

        select, button {
            font-size: 14px;
            padding: 6px 8px;
            border-radius: 6px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            background: rgba(255, 255, 255, 0.06);
            color: #fff;
            cursor: pointer;
        }

        .note {
            position: fixed;
            left: 12px;
            bottom: 12px;
            z-index: 10;
            color: #fff;
            background: rgba(0, 0, 0, 0.25);
            padding: 8px 10px;
            border-radius: 6px;
            font-size: 13px;
        }
    </style>
    <style>
        #container {
            position: fixed;
            bottom: 0;
            /*position: relative;*/
            z-index: 10;
            padding: 12px;
            display: flex;
            gap: 8px;
            align-items: center;
            background: rgba(0, 0, 0, 0.35);
            color: #fff;
            border-radius: 8px;
            margin: 12px;
            /*width: max-content;*/
            /*left: 0;*/
            width: 90%;
            /*background: white;*/
            /*border-top: 2px solid #ccc;*/
            /*z-index: 10; !* highest priority *!*/
            /*display: flex;*/
            /*align-items: flex-start;*/
            /*padding: 8px;*/
            /*box-shadow: 0 -2px 8px rgba(0, 0, 0, 0.2);*/
        }

        #listContainer {
            height: 120px;
            flex: 1;
            border: 1px solid #ccc;
            overflow-y: auto;
            padding: 0 10px;
            font-family: Arial, sans-serif;
            color: #ccc;
            background: rgba(0, 0, 0, 0.35);
        }

        #itemList {
            list-style: none;
            margin: 0;
            padding: 0;
        }

        #itemList li {
            border-bottom: 1px solid #eee;
            padding: 4px 0;
        }

        #listrefreshBtn {
            margin-left: 8px;
            height: 40px;
            align-self: center;
        }
    </style>
</head>
<body>
<video id="bgVideo" autoplay playsinline muted></video>
<canvas id="freezeCanvas"
        style="display:none;position:fixed;inset:0;width:100%;height:100%;object-fit:cover;z-index:0;"></canvas>
<canvas id="resultCanvas"
        style="display:none;position:fixed;inset:0;width:100%;height:100%;object-fit:cover;z-index:0;"></canvas>

<div class="ui">
    <label for="cameraSelect">Camera</label>
    <select id="cameraSelect"></select>
    <button id="startBtn">Start</button>
    <button id="refreshBtn" title="Refresh device list">⟳</button>
</div>

<div id="container">
    <div id="listContainer">
        <ul id="itemList"></ul>
    </div>
    <button id="listrefreshBtn">Refresh</button>
</div>
<!--<div class="note">Tip: Works best on HTTPS or localhost. Grant permission to see camera names.</div>-->
<script src="https://cdn.jsdelivr.net/npm/@vladmandic/human@3.3.5/dist/human.js"></script>

<script>
    (async () => {
        const human = new Human.Human({
            backend: 'webgl', // Try 'wasm' if WebGL fails
            modelBasePath: 'https://cdn.jsdelivr.net/npm/@vladmandic/human@3.3.5/models/',
            face: {
                enabled: true,
                detector: {rotation: true, return: true, mask: false}, // return tensor is used to get detected face image
                description: {enabled: true}, // default model for face descriptor extraction is faceres
                // mobilefacenet: { enabled: true, modelPath: 'https://vladmandic.github.io/human-models/models/mobilefacenet.json' }, // alternative model
                // insightface: { enabled: true, modelPath: 'https://vladmandic.github.io/insightface/models/insightface-mobilenet-swish.json' }, // alternative model
                iris: {enabled: true}, // needed to determine gaze direction
                emotion: {enabled: false}, // not needed
                antispoof: {enabled: true}, // enable optional antispoof module
                liveness: {enabled: true}, // enable optional liveness module
            },
            body: {enabled: false},
            hand: {enabled: false},
            object: {enabled: false},
            gesture: {enabled: true}, // parses face and iris gestures
        });
        human.env.perfadd = false; // is performance data showing instant or total values
        human.draw.options.font = 'small-caps 18px "Lato"'; // set font used to draw labels when using draw methods
        human.draw.options.lineHeight = 20;
        await human.load();
        await human.warmup();
        // Retrieve existing list (or create empty)
        let embeddingsList = sessionStorage.getItem('faceEmbeddings');


        const dom = {
            resultCanvas: document.getElementById('resultCanvas'),
            freezeCanvas: document.getElementById('freezeCanvas'),
            video: document.getElementById('bgVideo'),
        }

        const video = document.getElementById('bgVideo');
        const select = document.getElementById('cameraSelect');
        const startBtn = document.getElementById('startBtn');
        const refreshBtn = document.getElementById('refreshBtn');


        let currentStream = null;
        let lastDetectedFace = null;
        let paused = false;
        let bufferCanvas = null;

        function euclideanDistance(a, b) {
            let sum = 0;
            for (let i = 0; i < a.length; i++) {
                const diff = a[i] - b[i];
                sum += diff * diff;
            }
            return Math.sqrt(sum);
        }

        // Function to check if new embedding matches any in embeddingsList
        function isFaceKnown(newEmbedding, threshold = 0.6) {
            let embeddingsList = sessionStorage.getItem('faceEmbeddings');
            if (embeddingsList) {
                embeddingsList = JSON.parse(embeddingsList);
                // Convert each stored array back to Float32Array if needed
                embeddingsList = embeddingsList.map(arr => new Float32Array(arr));
                console.log('All embeddings:', embeddingsList);
            } else {
                embeddingsList = [];
                console.log('No embeddings found');
            }
            for (const storedEmbedding of embeddingsList) {
                const dist = euclideanDistance(newEmbedding, storedEmbedding);
                if (dist < threshold) {
                    return true; // match found
                }
            }
            // No match found — add new embedding to list and save it
            embeddingsList.push(newEmbedding);
            sessionStorage.setItem('faceEmbeddings', JSON.stringify(embeddingsList.map(e => Array.from(e))));

            return false; // no match
        }

        async function detectVideo() {
            try {
                let result;
                bufferCanvas = dom.freezeCanvas;
                if (dom.video.end) {
                    requestAnimationFrame(detectVideo);
                    return;
                }
                if (!paused) {
                    bufferCanvas = document.createElement('canvas');
                    bufferCanvas.width = dom.video.videoWidth;
                    bufferCanvas.height = dom.video.videoHeight;
                    const bufferCtx = bufferCanvas.getContext('2d');
                    bufferCtx.drawImage(video, 0, 0);
                }

                result = await human.detect(bufferCanvas);


                dom.resultCanvas.style.display = 'none';
                // Make canvas same size as video element (or window, as needed)
                dom.resultCanvas.width = dom.video.videoWidth;   // internal canvas pixel width
                dom.resultCanvas.height = dom.video.videoHeight; // internal canvas pixel height

                // Optionally set CSS size too, if you want full screen visually
                dom.resultCanvas.style.width = '100vw';  // viewport width
                dom.resultCanvas.style.height = '100vh'; // viewport height

                if (result.face && result.face.length > 0) {
                    const ctx = dom.resultCanvas.getContext('2d');
                    ctx.clearRect(0, 0, dom.resultCanvas.width, dom.resultCanvas.height);
                    ctx.strokeStyle = 'green';
                    ctx.lineWidth = 2;

                    // const interpolated = human.next(human.result); // smoothen result using last-known results
                    // if (!paused) human.draw.canvas(dom.video, dom.resultCanvas); // draw canvas to screen
                    // await human.draw.all(dom.resultCanvas, interpolated); // draw labels, boxes, lines, etc.


                    console.log('Faces detected:', result.face.length);

                    for (const face of result.face) {
                        try {
                            // detecting logic
                            if (face.box && face.live > 0.7 && face.real > 0.7) {
                                const is_new_face = !isFaceKnown(face.embedding, 0.6);
                                lastDetectedFace = face;

                                const [x, y, w, h] = face.box;

                                // Draw bounding box
                                ctx.strokeRect(x, y, w, h);
                                if (is_new_face) {
                                    // Crop from frozen frame
                                    const cropCanvas = document.createElement('canvas');
                                    cropCanvas.width = w;
                                    cropCanvas.height = h;
                                    const cropCtx = cropCanvas.getContext('2d');
                                    cropCtx.drawImage(bufferCanvas, x, y, w, h, 0, 0, w, h);

                                    // Convert to blob & send to server
                                    cropCanvas.toBlob(async (blob) => {
                                        try {
                                            const formData = new FormData();
                                            formData.append('face_image', blob, 'face.jpg');

                                            await fetch('/upload_face', {
                                                method: 'POST',
                                                body: formData
                                            });
                                        } catch (uploadErr) {
                                            console.error('Upload failed:', uploadErr);
                                        }
                                    }, 'image/jpeg', 0.9); // JPEG quality 90%
                                }
                            }
                        } catch (faceErr) {
                            console.error('Error processing face:', faceErr);
                        }
                    }
                    dom.resultCanvas.style.display = 'block';
                } else {
                    console.log('No faces detected');
                }
            } catch (err) {
                console.error('Detection error:', err.name, err.message);
            }

            requestAnimationFrame(detectVideo);
        }

        async function populateCameraList() {
            select.innerHTML = '';
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const cams = devices.filter(d => d.kind === 'videoinput');
                if (cams.length === 0) {
                    select.innerHTML = '<option>No camera found</option>';
                    select.disabled = true;
                    return;
                }
                cams.forEach((cam, i) => {
                    const opt = document.createElement('option');
                    opt.text = cam.label || `Camera ${i + 1}`;
                    opt.value = cam.deviceId;
                    select.appendChild(opt);
                });
                select.disabled = false;
            } catch (err) {
                console.error('Error enumerating devices:', err);
                select.innerHTML = '<option>Device list unavailable</option>';
                select.disabled = true;
            }
        }

        async function startStream(deviceId) {
            stopStream();
            paused = false;
            const constraints = {
                audio: false,
                video: deviceId ? {deviceId: {exact: deviceId}} : {facingMode: 'environment'}
            };
            try {
                currentStream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = currentStream;
                startBtn.disabled = true;
                await populateCameraList();
                if (deviceId) select.value = deviceId;
            } catch (err) {
                console.error('getUserMedia error:', err);
                alert('Cannot start camera: ' + (err.message || err.name));
            }
        }


        function stopStream() {
            if (currentStream) {
                currentStream.getTracks().forEach(t => t.stop());
                currentStream = null;
            }
            video.srcObject = null;
            startBtn.disabled = false;
            paused = false;
        }

        navigator.mediaDevices?.addEventListener?.('devicechange', populateCameraList);

        startBtn.addEventListener('click', () => startStream(select.value || ''));
        refreshBtn.addEventListener('click', populateCameraList);
        select.addEventListener('change', () => {
            if (currentStream) startStream(select.value);
        });


        await populateCameraList();
        detectVideo();

    })();
</script>
<script>
    const listrefreshBtn = document.getElementById('listrefreshBtn');
    const itemList = document.getElementById('itemList');

    async function fetchAndShowList() {
        try {

            const response = await fetch('/get_named');
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }
            const data = await response.json();
            console.log('receive' + data);
            if (Array.isArray(data)) {
                updateList(data);
            } else {
                console.error('Response data is not an array:', data);
            }
        } catch (error) {
            console.error('Error fetching list:', error);
        }
    }

    function updateList(items) {
        itemList.innerHTML = ''; // Clear existing items
        for (const item of items) {
            const li = document.createElement('li');
            li.textContent = item;
            itemList.appendChild(li);
        }
    }

    listrefreshBtn.addEventListener('click', fetchAndShowList);

    // Optionally fetch once on page load:
    fetchAndShowList();
</script>
</body>
</html>
